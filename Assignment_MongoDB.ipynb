{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qnGAdEirXtHX"
      },
      "outputs": [],
      "source": [
        "##Theoritical Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que1: What are the key differences between SQL and NoSQL databases?\n",
        "\n",
        "Ans1: SQL databases are relational, use structured schemas, and support SQL queries. NoSQL databases like MongoDB are non-relational, support dynamic schemas, and store data in flexible formats (e.g., JSON). SQL ensures ACID compliance; NoSQL offers scalability and high performance for unstructured data."
      ],
      "metadata": {
        "id": "2ZS5UF-pZe7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que2: What makes MongoDB a good choice for modern applications?\n",
        "\n",
        "Ans2: MongoDB offers flexible document-based storage, horizontal scalability, and a powerful query language. It handles unstructured and semi-structured data efficiently, making it ideal for real-time analytics, content management, IoT, and mobile apps."
      ],
      "metadata": {
        "id": "rFB3tzgKZcNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que3: Explain the concept of collections in MongoDB?\n",
        "\n",
        "Ans3: Collections in MongoDB are analogous to tables in SQL. They store groups of related documents (records), each having a dynamic schema. Collections enable flexible, schema-less storage for varied data types within the same dataset."
      ],
      "metadata": {
        "id": "ib1bTXAqZZIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que4: How does MongoDB ensure high availability using replication?\n",
        "\n",
        "Ans4: MongoDB uses replica sets to ensure high availability. A replica set includes a primary node and multiple secondary nodes. Data is automatically replicated across nodes, and if the primary fails, a secondary is promoted to primary automatically."
      ],
      "metadata": {
        "id": "xiYPQUOfZWIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que5: What are the main benefits of MongoDB Atlas?\n",
        "\n",
        "Ans5: MongoDB Atlas is a fully managed cloud database offering auto-scaling, backups, real-time performance monitoring, global distribution, and built-in security. It eliminates infrastructure management and ensures high availability and scalability across major cloud providers."
      ],
      "metadata": {
        "id": "JDfPcyz9ZS7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que6: What is the role of indexes in MongoDB, and how do they improve performance?\n",
        "\n",
        "Ans6: Indexes improve query performance by allowing MongoDB to locate data efficiently without scanning the entire collection. Common indexes include single-field, compound, and text indexes. Without indexes, queries are slower and more resource-intensive."
      ],
      "metadata": {
        "id": "NTPPqpCUZP9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que7: Describe the stages of the MongoDB aggregation pipeline?\n",
        "\n",
        "Ans7: The aggregation pipeline processes data through stages like $match (filtering), $group (aggregation), $sort, $project (reshaping), and $lookup (joins). Each stage transforms the documents, enabling powerful data analysis and reporting."
      ],
      "metadata": {
        "id": "W7j4RXXxZM_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que8: What is sharding in MongoDB? How does it differ from replication?\n",
        "\n",
        "Ans8: Sharding partitions data across multiple servers for horizontal scaling, improving performance and storage. Replication copies data across servers to ensure high availability. Sharding handles large datasets; replication ensures fault tolerance."
      ],
      "metadata": {
        "id": "uovQ2vIlZKAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que9: What is PyMongo, and why is it used?\n",
        "\n",
        "Ans9: PyMongo is the official Python driver for MongoDB. It enables Python applications to interact with MongoDB databases for CRUD operations, aggregation, indexing, and more, making it essential for integrating MongoDB with Python-based apps."
      ],
      "metadata": {
        "id": "0JOeu8qwZGsg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que10: What are the ACID properties in the context of MongoDB transactions?\n",
        "\n",
        "Ans10: ACID stands for Atomicity, Consistency, Isolation, and Durability. MongoDB supports multi-document transactions with ACID guarantees, ensuring reliable and consistent data updates, especially important for financial and enterprise applications."
      ],
      "metadata": {
        "id": "otmL6NMLZCN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que11: What is the purpose of MongoDB's explain() function?\n",
        "\n",
        "Ans11: The explain() function reveals how MongoDB executes a query, including index usage, scan type, and execution time. It helps developers optimize performance by identifying inefficiencies in query plans."
      ],
      "metadata": {
        "id": "zQ1bzV8HY_AX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que12: How does MongoDB handle schema validation?\n",
        "\n",
        "Ans12: MongoDB allows schema validation using JSON Schema. It enforces rules on document structure and field types within a collection, ensuring data consistency while still supporting flexibility where needed."
      ],
      "metadata": {
        "id": "amghnj6eY5bJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que13: What is the difference between a primary and a secondary node in a replica set?\n",
        "\n",
        "Ans13: The primary node handles all write operations, while secondary nodes replicate the data from the primary and serve read queries (if enabled). In failover scenarios, a secondary can become primary."
      ],
      "metadata": {
        "id": "330Yh3sNY3Au"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que14: What security mechanisms does MongoDB provide for data protection?\n",
        "\n",
        "Ans14: MongoDB provides authentication, role-based access control, TLS/SSL encryption, auditing, IP whitelisting, and encryption at rest. These features ensure secure access, data protection, and compliance with security standards."
      ],
      "metadata": {
        "id": "rRHQf7MBYzc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que15: Explain the concept of embedded documents and when they should be used?\n",
        "\n",
        "Ans15: Embedded documents store related data within a single document, improving read performance and reducing joins. Use them when related data is accessed together and when document size stays within BSON limits (16MB)."
      ],
      "metadata": {
        "id": "j4BCDlgeYuzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que16: What is the purpose of MongoDB's $lookup stage in aggregation?\n",
        "\n",
        "Ans16: $lookup performs left outer joins between collections. It allows combining documents from multiple collections in a single aggregation pipeline, useful for referencing related data like orders and customers."
      ],
      "metadata": {
        "id": "UWj9krJ2Yq_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que17: What are some common use cases for MongoDB?\n",
        "\n",
        "Ans17: MongoDB is widely used for content management, IoT, real-time analytics, e-commerce platforms, mobile apps, catalog systems, and any application needing flexible data models and scalable storage."
      ],
      "metadata": {
        "id": "dR67zf4zYm28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que18: What are the advantages of using MongoDB for horizontal scaling?\n",
        "\n",
        "Ans18: MongoDB supports horizontal scaling through sharding, distributing data across multiple nodes. This allows handling large volumes of data and traffic with minimal performance loss, ensuring seamless scalability."
      ],
      "metadata": {
        "id": "3fCFl31SYiku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que19: How do MongoDB transactions differ from SQL transactions?\n",
        "\n",
        "Ans19: MongoDB supports multi-document ACID transactions, similar to SQL. However, SQL is inherently transactional across rows and tables, while MongoDB's transactional features were introduced later and are typically used only when needed."
      ],
      "metadata": {
        "id": "pKKUwmPDYcWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que20: What are the main differences between capped collections and regular collections?\n",
        "\n",
        "Ans20: Capped collections are fixed-size, automatically overwrite oldest documents, and maintain insertion order—ideal for logs or cache. Regular collections have no size limits and support document deletion and updates."
      ],
      "metadata": {
        "id": "MD0nI-EKYZG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que21: What is the purpose of the $match stage in MongoDB's aggregation pipeline?\n",
        "\n",
        "Ans21: $match filters documents based on specific criteria, similar to a SQL WHERE clause. It's often placed early in the pipeline to reduce the number of documents processed in later stages."
      ],
      "metadata": {
        "id": "vgxVFQ-fYQMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que22: How can you secure access to a MongoDB database?\n",
        "\n",
        "Ans22: Secure MongoDB by enabling authentication, using strong passwords, enforcing role-based access control, encrypting connections with TLS/SSL, restricting network access via firewalls/IP whitelisting, and using encrypted storage."
      ],
      "metadata": {
        "id": "AkaZUOyVYMj1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que23: What is MongoDB's WiredTiger storage engine, and why is it important?\n",
        "\n",
        "Ans23: WiredTiger is MongoDB's default storage engine. It provides document-level concurrency, data compression, and efficient memory usage. It improves performance and scalability, especially in write-intensive and concurrent workloads."
      ],
      "metadata": {
        "id": "aekewizSX4ss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Practical Questions"
      ],
      "metadata": {
        "id": "Nsc-HWNtcHVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymongo pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFVWLI43c_8K",
        "outputId": "b5afa5db-3c50-4b31-f037-77151732837e",
        "collapsed": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tGCj8T9dQqC",
        "outputId": "e4908ff3-0932-4828-941e-0e8e2d1bb15e",
        "collapsed": true
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.7.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que1: Write a Python script to load the Superstore dataset from a CSV file into MongoDB."
      ],
      "metadata": {
        "id": "1GQ3Ur_rcPCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans1:\n",
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "import gdown\n",
        "\n",
        "# Download the CSV from Google Drive\n",
        "gdrive_url = \"https://drive.google.com/uc?id=1bJ-X2ONfnE5YbsNe2bCK39IfoBHexYQO\"\n",
        "output_file = \"Superstore.csv\"\n",
        "gdown.download(gdrive_url, output_file, quiet=False)\n",
        "\n",
        "# Connect to local MongoDB\n",
        "client = MongoClient(\"mongodb+srv://Google-ColabProjects:12test34@cluster0.edvxzj6.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
        "db = client[\"SuperstoreDB\"]\n",
        "collection = db[\"Orders\"]\n",
        "\n",
        "# Load CSV with correct encoding\n",
        "df = pd.read_csv(output_file, encoding=\"ISO-8859-1\")  # or encoding=\"latin1\"\n",
        "data = df.to_dict(orient=\"records\")\n",
        "\n",
        "# Insert into MongoDB\n",
        "collection.insert_many(data)\n",
        "print(\"Data loaded into MongoDB.\")\n",
        "\n",
        "collection.delete_many({})  # Clears existing documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwSSyMUVdpYq",
        "outputId": "d0a6e145-30ee-4360-b1d6-c91e87814ca5",
        "collapsed": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bJ-X2ONfnE5YbsNe2bCK39IfoBHexYQO\n",
            "To: /content/Superstore.csv\n",
            "100%|██████████| 2.29M/2.29M [00:00<00:00, 194MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded into MongoDB.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeleteResult({'n': 9994, 'electionId': ObjectId('7fffffff00000000000000f0'), 'opTime': {'ts': Timestamp(1752909940, 922), 't': 240}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1752909940, 924), 'signature': {'hash': b'\"\\x0fz\\xb3\\xec*\\xd4X>)c\\xdb\\xa9\\xe8\\xbd;\\xec\\xb3\\x85H', 'keyId': 7482727795873808386}}, 'operationTime': Timestamp(1752909940, 922)}, acknowledged=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que2: Retrieve and print all documents from the Orders collection."
      ],
      "metadata": {
        "id": "m4-bQmW0jD0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans2:\n",
        "print(\"\\nAll documents:\")\n",
        "for doc in collection.find():\n",
        "    print(doc)"
      ],
      "metadata": {
        "id": "a5AVXjDUdY0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "3f432ae4-6b0b-42f0-94b4-c65b0edb1a7d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All documents:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que3: Count and display the total number of documents in the Orders collection."
      ],
      "metadata": {
        "id": "6HfWaWoLjKqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans3:\n",
        "count = collection.count_documents({})\n",
        "print(f\"\\nTotal number of documents: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZL5ZTqXFjTdb",
        "outputId": "9f388758-effa-4901-b4bf-ce84effad030"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total number of documents: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que4: Write a query to fetch all orders from the \"West\" region."
      ],
      "metadata": {
        "id": "KFH9q1sKjxeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans4:\n",
        "west_orders = collection.find({\"Region\": \"West\"})\n",
        "print(\"\\nOrders from West region:\")\n",
        "for doc in west_orders:\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "81vMqd7ujxB2",
        "outputId": "e63cdd31-349f-44a4-896b-ed1d927b6585"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Orders from West region:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que5: Write a query to find orders where Sales is greater than 500."
      ],
      "metadata": {
        "id": "PJpauOd1jvsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans5:\n",
        "high_sales = collection.find({\"Sales\": {\"$gt\": 500}})\n",
        "print(\"\\nOrders with Sales > 500:\")\n",
        "for doc in high_sales:\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YWH0sUFljvJl",
        "outputId": "7feee8e2-b173-4269-d554-df86e5f36fc7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Orders with Sales > 500:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que6: Fetch the top 3 orders with the highest Profit."
      ],
      "metadata": {
        "id": "VaLIWM3Bjsoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans6:\n",
        "top_profit_orders = collection.find().sort(\"Profit\", -1).limit(3)\n",
        "print(\"\\nTop 3 profitable orders:\")\n",
        "for doc in top_profit_orders:\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IPPc3nFSjsZI",
        "outputId": "81c344e7-f5ce-451a-c433-d26afa5fa8b7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 3 profitable orders:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que7: Update all orders with Ship Mode as \"First Class\" to \"Premium Class."
      ],
      "metadata": {
        "id": "lRlOdBeMjofL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans7:\n",
        "update_result = collection.update_many(\n",
        "    {\"Ship Mode\": \"First Class\"},\n",
        "    {\"$set\": {\"Ship Mode\": \"Premium Class\"}}\n",
        ")\n",
        "print(f\"\\nUpdated {update_result.modified_count} documents.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qRIrIhRFjoQE",
        "outputId": "eeec14fe-0c4d-4f57-c97a-b8f707985614"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated 0 documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que8: Delete all orders where Sales is less than 50."
      ],
      "metadata": {
        "id": "uU1imyFBjhtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans8:\n",
        "delete_result = collection.delete_many({\"Sales\": {\"$lt\": 50}})\n",
        "print(f\"\\nDeleted {delete_result.deleted_count} documents.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kXUAMNNbjhfJ",
        "outputId": "f2dd1874-5e3c-4594-9a98-3977f2dbb58c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Deleted 0 documents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que9: Use aggregation to group orders by Region and calculate total sales per region."
      ],
      "metadata": {
        "id": "Gk8kR3Xwje7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans9:\n",
        "pipeline = [\n",
        "    {\"$group\": {\"_id\": \"$Region\", \"total_sales\": {\"$sum\": \"$Sales\"}}}\n",
        "]\n",
        "region_sales = collection.aggregate(pipeline)\n",
        "print(\"\\nTotal Sales per Region:\")\n",
        "for doc in region_sales:\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FK4GtKRjjeqv",
        "outputId": "ae7b22fb-5576-4f65-dfb5-5703f42a4911"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total Sales per Region:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que10: Fetch all distinct values for Ship Mode from the collection."
      ],
      "metadata": {
        "id": "kGktj1t_jZzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans10:\n",
        "distinct_modes = collection.distinct(\"Ship Mode\")\n",
        "print(\"\\nDistinct Ship Modes:\")\n",
        "print(distinct_modes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7KWkAt4ejZda",
        "outputId": "b446a277-549d-474c-f490-ba2ff2f396c5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distinct Ship Modes:\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que11: Count the number of orders for each category."
      ],
      "metadata": {
        "id": "1G8DHE6BjWif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans11:\n",
        "category_count = collection.aggregate([\n",
        "    {\"$group\": {\"_id\": \"$Category\", \"order_count\": {\"$sum\": 1}}}\n",
        "])\n",
        "print(\"\\nNumber of orders per Category:\")\n",
        "for doc in category_count:\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3KCx4V0EjWBX",
        "outputId": "783d97ec-1112-41cf-90db-a330eafb9033"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of orders per Category:\n"
          ]
        }
      ]
    }
  ]
}